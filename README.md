Namaste nanhe programmers aur data scientists! ğŸ‘‹

Pichhle session mein humne ek Decision Tree robot banaya tha jo flowers ko pehchanta hai. Aaj hum us kaam ko thoda aur organize karenge, bilkul aise jaise koi bada project karte waqt hum cheezon ko alag alag boxes ya rooms mein rakhte hain. Is organised tareeke ko **Pipeline** kehte hain. Socho Pipeline ek lambi line hai jismein har step par ek alag **helper robot** kaam karta hai! ğŸ¤–â¡ï¸âš™ï¸â¡ï¸ğŸ“Šâ¡ï¸âœ¨

Yeh Pipeline banane se hamara code clean rehta hai, samajhne mein aasan hota hai, aur agar koi problem aaye toh pata lagana easy ho jata hai ki kaunsa helper robot gadbad kar raha hai.

Humne jo code diya hai, usmein do main helper robots hain:
1.  **Data Processing Robot:** Yeh data ko saaf karega aur usko training aur testing ke liye ready karega.
2.  **Model Training Robot:** Yeh saaf data lekar hamare Decision Tree robot ko train karega aur dekhega ki usne test mein kaisa kiya.

Yeh saare helper robots alag alag Python files mein hain, jo ek folder mein organised hain. Chalo dekhte hain yeh kaise kaam karta hai, ekdum simple tareeke se! ğŸ˜ŠğŸš€

---

### ğŸ“š Hamare Pipeline Ebook Ka Safar (Table of Contents)

1.  **Introduction:** Pipeline Kya Hai? ğŸ¤”
2.  **Hamara Project Ka Structure:** Folders aur Files ğŸ“
3.  **Pehla Helper Robot: `logger.py` (Diary Wala Robot)** âœï¸
4.  **Dusra Helper Robot: `custom_exception.py` (Loud Error Reporter Robot)** ğŸ“¢
5.  **Teesra Helper Robot: `data_processing.py` (Data Cleaning Robot)** âœ¨
    *   Setting up the Workspace (`__init__`)
    *   Loading the Raw Data (`load_data`)
    *   Fixing Shararti Numbers (Outliers) (`handle_outliers`)
    *   Dividing Data (Train/Test Split) (`split_data`)
    *   Data Robot Ka To-Do List (`run`)
6.  **Chautha Helper Robot: `model_training.py` (Robot Trainer)** ğŸ¤–
    *   Setting up the Schoolroom (`__init__`)
    *   Getting Ready Data (`load_data`)
    *   Robot Ko Sikhana (`train_model`)
    *   Robot Ka Test Lena (`evaluate_model`)
    *   Trainer Robot Ka To-Do List (`run`)
7.  **Master Controller: `training_pipeline.py` (The Recipe Book)** ğŸ“œ
8.  **Diagrams/Image Suggestions** ğŸ–¼ï¸
9.  **Glossary: Naye aur Purane Shabdon Ka Matlab** ğŸ“–
10. **Summary: Poora Pipeline Kaise Chalta Hai?** ğŸ‰

---

### 1. Introduction: Pipeline Kya Hai? ğŸ¤”

Socho, aapko sandwich banana hai. Aap seedha khana shuru nahi kar dete! Pehle bread lete ho, fir uspar butter lagate ho, fir filling daalte ho, fir dusra bread rakhte ho, aur tab khate ho. Yeh ek **step-by-step process** hai.

Machine Learning mein bhi hum aisa hi step-by-step process banate hain.
1.  Data Collect karo (Yeh hamare paas pehle se hai: `data.csv` file mein).
2.  Data ko Saaf karo (Agar koi galti ho ya missing information ho).
3.  Data ko Ready karo (Training aur Testing ke liye).
4.  Robot ko Train karo data se.
5.  Robot ko Test karo ki woh kaisa seekha hai.

Yeh saare steps milkar ek **Pipeline** banate hain. Humne is pipeline ko alag alag Python files aur classes (jaise blueprints for helper robots) mein divide kiya hai.

---

### 2. Hamara Project Ka Structure: Folders aur Files ğŸ“

Apne kaam ko organise karne ke liye hum files ko folders mein rakhte hain. Socho jaise school bag mein alag alag subjects ki books alag alag pockets mein rakhte hain.

Hamare project ka structure kuch aisa dikhega:

```
your_project_folder/
â”‚
â”œâ”€â”€ artifacts/             <-- Yeh hamara 'storage room' hai
â”‚   â”œâ”€â”€ raw/               <-- Yahan kaccha (raw) data rakha hai
â”‚   â”‚   â””â”€â”€ data.csv
â”‚   â””â”€â”€ processed/         <-- Yahan saaf aur ready data rakha jayega (jab code chalega)
â”‚   â””â”€â”€ models/            <-- Yahan hamara trained robot (model) aur test reports rakhe jayenge (jab code chalega)
â”‚
â”œâ”€â”€ pipeline/              <-- Yeh hamari 'recipe book' hai
â”‚   â””â”€â”€ training_pipeline.py <-- Main file jo sab kuch chalaegi
â”‚
â””â”€â”€ src/                   <-- Yeh hamare 'helper robots' ka ghar hai
    â”œâ”€â”€ custom_exception.py  <-- Error Reporter Robot
    â”œâ”€â”€ data_processing.py   <-- Data Cleaning Robot
    â”œâ”€â”€ logger.py            <-- Diary Wala Robot
    â””â”€â”€ model_training.py    <-- Robot Trainer
    
```
*   **Explanation:** `artifacts` folder woh jagah hai jahan hamare data aur trained robot jaisi important cheezein store hongi. `raw` mein asli data hai, aur jab hum code chalayenge toh `processed` aur `models` folders automatically ban jayenge aur unmein data save hoga. `pipeline` folder mein woh file hai jo poore process ko shuru karegi. `src` folder mein hamare main helper robots (Python files) rehte hain jo specific kaam karte hain.

---

### 3. Pehla Helper Robot: `logger.py` (Diary Wala Robot) âœï¸

Sabse pehle, hamara ek chota robot hai jo bas diary likhta hai. Jab hamare do main robots kaam kar rahe honge, toh yeh Diary Wala Robot sab kuch note karega - kaunsa step kab shuru hua, kya kaam hua, koi galti toh nahi hui. Yeh bade programmers ke liye bahut helpful hota hai dekhne ke liye ki code smoothly chal raha hai ya nahi. Hamare liye, yeh bas batata hai ki kab kaunsa kaam ho raha hai.

Yeh raha is robot ka code:

```python
# src/logger.py

import logging
import os
from datetime import datetime

# Ek folder banate hain jahan diary entries save hongi
LOGS_DIR = "logs"
os.makedirs(LOGS_DIR,exist_ok=True) # Agar folder pehle se hai toh theek hai

# Diary file ka naam (Aaj ki date ke saath)
LOG_FILE = os.path.join(LOGS_DIR, f"log_{datetime.now().strftime('%Y-%m-%d')}.log")

# Diary mein kya kya likhna hai aur kis format mein likhna hai, yeh batate hain
logging.basicConfig(
    filename=LOG_FILE, # Kis file mein likhna hai
    format='%(asctime)s - %(levelname)s - %(message)s', # Kaise dikhe entry (time - level - message)
    level=logging.INFO # Sirf important messages (INFO level aur usse upar) likho
)

# Ek function jo diary entry likhne mein help karega
def get_logger(name):
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO) # Is specific diary mein bhi INFO level messages likho
    return logger # Diary entry robot wapas bhej do use karne ke liye

```

*   **Explanation:** Yeh code ek folder (`logs`) banata hai aur uske andar aaj ki date wali ek file (`log_YYYY-MM-DD.log`). Phir yeh set karta hai ki diary entries kis tarah likhi jayengi (date, time, message type, aur message). `get_logger` function dusre files ko ek Diary Wala Robot deta hai jo is set kiye gaye tarike se entries likh sakta hai. Jab hamare do main robots chalenge, woh is Diary Wale Robot ko use karke bataenge ki woh kya kar rahe hain.

---

### 4. Dusra Helper Robot: `custom_exception.py` (Loud Error Reporter Robot) ğŸ“¢

Jab hamara code chal raha hota hai, kabhi kabhi galtiyan ho jati hain. Jab koi galti hoti hai, Python ek **Exception** throw karta hai (jaise robot chilla kar bolta hai "Mujhse yeh nahi ho raha!"). Normal galti ka message kabhi kabhi samajh nahi aata ki problem kahaan hai.

Hamara Loud Error Reporter Robot ek special tarah ka "chillana" banata hai jismein woh detailed report deta hai ki galti kya hai aur yeh kis file ki kis line mein hui. Isse hamare liye problem theek karna aasan ho jata hai. Socho, yeh bas galti ko aur clear aur helpful tarike se batane wala robot hai.

Yeh raha is robot ka code:

```python
# src/custom_exception.py

import sys # System ki jankari lene ke liye

# Hamara apna special tarah ka error reporter banate hain
class CustomException(Exception): # Yeh normal Exception wali family se hai
    def __init__(self, message: str, error_detail: Exception = None):
        # Jab yeh reporter banega, isko ek message aur original galti (error_detail) do
        self.error_message = self.get_detailed_error_message(message, error_detail)
        super().__init__(self.error_message) # Parent Exception class ko hamara detailed message de do

    @staticmethod # Yeh function seedha class se use ho sakta hai, robot banane ki zarurat nahi
    def get_detailed_error_message(message, error_detail):
        """Error message ko detail mein format karta hai (kahaan galti hui)."""
        _, _, exc_tb = sys.exc_info() # Galti ke time ki details nikalo
        # Pata lagao ki kaunsi file aur kaunsi line mein galti hui
        file_name = exc_tb.tb_frame.f_code.co_filename if exc_tb else "Unknown File"
        line_number = exc_tb.tb_lineno if exc_tb else "Unknown Line"
        # Ek achha detailed message banao
        return f"{message} | Error: {error_detail} | File: {file_name} | Line: {line_number}"

    def __str__(self):
        """Jab is reporter ko print karenge, toh yeh message dikhega."""
        return self.error_message

```

*   **Explanation:** Yeh code ek special class `CustomException` banata hai. Jab bhi hamare main robots ko lagega ki koi galti ho sakti hai, woh is class ko use karke ek detailed error message generate karenge. Ismein error ka description, original galti ka detail, aur galti kis file ki kis line mein hui, yeh sab included hota hai. Yeh error handling ko bahut powerful bana deta hai, jaise ek auto-generated problem report!

---

### 5. Teesra Helper Robot: `data_processing.py` (Data Cleaning Robot) âœ¨

Yeh hamara pehla main helper robot hai pipeline mein. Iska kaam hai kacche data ko lena (`data.csv`), usko saaf karna (outliers theek karna), aur usko training aur testing ke liye do parts mein divide karna. Phir yeh saaf data ko special boxes (`.pkl` files) mein pack karke `artifacts/processed` folder mein save kar deta hai.

Yeh Data Cleaning Robot ek `DataProcessing` class ke roop mein bana hai:

```python
# src/data_processing.py

import pandas as pd # Smart table wala tool
import numpy as np # Numbers wala tool
import joblib # Cheezein save aur load karne wala tool
from sklearn.model_selection import train_test_split # Data divide karne wala tool
import os # Folders aur files manage karne wala tool
from src.logger import get_logger # Diary Wala Robot import kiya
from src.custom_exception import CustomException # Error Reporter Robot import kiya

# Diary Wala Robot ka ek instance (copy) banate hain is file ke liye
logger = get_logger(__name__)

# Data Cleaning Robot ka blueprint (Class)
class DataProcessing:
    # Jab yeh robot banega, sabse pehle yeh steps honge
    def __init__(self,file_path):
        self.file_path = file_path # Kacche data file ka path yaad rakho
        self.df = None # Abhi table empty hai
        self.processed_data_path = "artifacts/processed" # Saaf data kahan save karna hai, woh path yaad rakho
        os.makedirs(self.processed_data_path , exist_ok=True) # Woh folder bana do agar nahi hai
        logger.info("Data Processing Robot Ready! ğŸ› ï¸") # Diary mein likho ki robot ready hai

    # Data ko kacche file se load karne ka kaam
    def load_data(self):
        try: # Yeh kaam try karo, agar galti ho toh catch karna
            self.df = pd.read_csv(self.file_path) # Data read karke table mein daalo
            logger.info("Raw data successfully loaded from %s", self.file_path) # Diary mein likho load ho gaya
        except Exception as e: # Agar galti hui
            logger.error(f"Error while reading data: {e}") # Diary mein galti likho
            raise CustomException("Failed to read data", e) # Loud Error Reporter ko bolo detail report de

    # Shararti numbers (outliers) ko theek karne ka kaam
    def handle_outliers(self, column): # Kis column ke outliers theek karne hain, yeh batao
        try:
            logger.info(f"Starting outlier handling for column: {column}") # Diary mein likho shuru ho gaya
            Q1 = self.df[column].quantile(0.25) # Data ka 25% point
            Q3 = self.df[column].quantile(0.75) # Data ka 75% point

            IQR = Q3 - Q1 # Beech ka range

            Lower_value = Q1 - 1.5 * IQR # Outlier ki lower limit
            Upper_value = Q3 + 1.5 * IQR # Outlier ki upper limit

            sepal_median = np.median(self.df[column]) # Jis value se replace karna hai (median)

            # Har number ko check karo aur agar outlier hai toh replace karo
            for i in self.df[column]:
                if i > Upper_value or i < Lower_value:
                    self.df[column] = self.df[column].replace(i, sepal_median)

            logger.info("Outliers handled successfully for column: %s", column) # Diary mein likho ho gaya
        except Exception as e:
            logger.error(f"Error while handling outliers for column {column}: {e}") # Diary mein galti likho
            raise CustomException(f"Failed to handle outliers for column {column}", e) # Loud Error Reporter ko bolo detail report de

    # Data ko train aur test sets mein divide karne ka kaam
    def split_data(self):
        try:
            # Inputs (features) aur output (target) columns alag karo
            X = self.df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]
            Y = self.df["Species"]
            logger.info("Features (X) and Target (Y) separated.") # Diary entry

            # Data ko 80% train aur 20% test mein baanto
            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)
            logger.info("Data split into training (80%) and testing (20%) sets.") # Diary entry

            # Saaf aur divided data ko special boxes mein pack karke save karo
            joblib.dump(X_train, os.path.join(self.processed_data_path, "X_train.pkl"))
            joblib.dump(X_test, os.path.join(self.processed_data_path, "X_test.pkl"))
            joblib.dump(y_train, os.path.join(self.processed_data_path, "y_train.pkl"))
            joblib.dump(y_test, os.path.join(self.processed_data_path, "y_test.pkl"))
            logger.info("Processed data files saved successfully in %s", self.processed_data_path) # Diary entry

        except Exception as e:
            logger.error(f"Error while splitting and saving data: {e}") # Diary mein galti likho
            raise CustomException("Failed to split and save data", e) # Loud Error Reporter ko bolo detail report de

    # Data Cleaning Robot ka main kaam (to-do list)
    def run(self):
        logger.info("Data Processing Pipeline Step Started.") # Diary entry
        self.load_data() # Pehla kaam: Data load karo
        # Doosra kaam: SepalWidthCm ke outliers theek karo (pichhle notebook mein bhi yeh hi kiya tha)
        self.handle_outliers("SepalWidthCm")
        self.split_data() # Teesra kaam: Data ko divide karke save karo
        logger.info("Data Processing Pipeline Step Finished Successfully.") # Diary entry

# Yeh code tabhi chalega jab aap seedha is file ko run karoge
# Agar is file ko pipeline/training_pipeline.py se chalayenge, toh yeh hissa nahi chalega
if __name__ == "__main__":
    # Sirf testing ke liye, aap seedha data processing chala sakte ho
    data_processor = DataProcessing("../artifacts/raw/data.csv") # Robot banao
    data_processor.run() # Robot ka kaam shuru karo

```

*   **Explanation:** Yeh file hamare Data Cleaning Robot ka blueprint (`DataProcessing` class) hai. Iske alag alag `def` functions iske alag alag kaam hain (load, clean, split). `__init__` function robot ko start karte waqt set up karta hai. `run` function robot ki puri to-do list hai. Har step par yeh Diary Wala Robot ko use karke entry likhta hai aur agar koi galti ho toh Loud Error Reporter Robot ko bula leta hai. Sabse important, yeh saaf kiye hue aur divided data ko `joblib.dump` use karke `.pkl` files mein save karta hai `artifacts/processed` folder mein, taki agla robot isko use kar sake. `joblib` ekdum special packing tool hai data ke liye.

---

### 6. Chautha Helper Robot: `model_training.py` (Robot Trainer) ğŸ¤–

Yeh hamara doosra main helper robot hai pipeline mein. Iska kaam hai `artifacts/processed` folder se saaf kiya hua data load karna, us data se Decision Tree robot ko train karna, train kiye hue robot ko save karna, aur fir test data par robot ka performance check karna aur uski report (confusion matrix) banana.

Yeh Robot Trainer ek `ModelTraining` class ke roop mein bana hai:

```python
# src/model_training.py

import joblib # Cheezein save aur load karne wala tool
import os # Folders aur files manage karne wala tool
from sklearn.tree import DecisionTreeClassifier # Decision Tree Robot banane wala tool
# Robot ke test marks check karne wale tools
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix
import matplotlib.pyplot as plt # Pictures (graphs) banane wala tool
import seaborn as sns # Sundar pictures banane wala tool
import numpy as np # Numbers wala tool
from src.logger import get_logger # Diary Wala Robot import kiya
from src.custom_exception import CustomException # Error Reporter Robot import kiya

# Diary Wala Robot ka ek instance (copy) banate hain is file ke liye
logger = get_logger(__name__)

# Robot Trainer ka blueprint (Class)
class ModelTraining:
    # Jab yeh robot banega, sabse pehle yeh steps honge
    def __init__(self):
        self.processed_data_path = "artifacts/processed" # Saaf data kahan hai, woh path yaad rakho
        self.model_path = "artifacts/models" # Train kiya hua robot kahan save karna hai, woh path yaad rakho
        os.makedirs(self.model_path , exist_ok=True) # Woh folder bana do agar nahi hai
        # Apna Decision Tree robot banao aur uski settings set karo
        self.model = DecisionTreeClassifier(criterion="gini" , max_depth=30 , random_state=42)
        logger.info("Model Training Robot Ready! ğŸ¤–") # Diary mein likho robot ready hai

    # Saaf data ko special boxes se load karne ka kaam
    def load_data(self):
        try:
            logger.info("Loading processed data...") # Diary mein likho shuru ho gaya
            # joblib.load use karke saare data files load karo
            X_train = joblib.load(os.path.join(self.processed_data_path , "X_train.pkl"))
            X_test = joblib.load(os.path.join(self.processed_data_path , "X_test.pkl"))
            y_train = joblib.load(os.path.join(self.processed_data_path , "y_train.pkl"))
            y_test = joblib.load(os.path.join(self.processed_data_path , "y_test.pkl"))
            logger.info("Processed data loaded successfully.") # Diary mein likho load ho gaya

            return X_train,X_test,y_train,y_test # Saara data wapas bhej do use karne ke liye

        except Exception as e:
            logger.error(f"Error while loading processed data: {e}") # Diary mein galti likho
            raise CustomException("Error while loading processed data", e) # Loud Error Reporter ko bolo detail report de

    # Decision Tree robot ko data se sikhane ka kaam
    def train_model(self, X_train, y_train): # Sikhane wala data lo
        try:
            logger.info("Starting model training...") # Diary mein likho shuru ho gaya
            self.model.fit(X_train,y_train) # Robot ko sikhao! Yeh hai training ka main step
            # Train kiye hue robot ko special box mein pack karke save karo
            joblib.dump(self.model, os.path.join(self.model_path, "model.pkl"))
            logger.info("Model trained and saved successfully in %s", self.model_path) # Diary mein likho train aur save ho gaya

        except Exception as e:
            logger.error(f"Error during model training: {e}") # Diary mein galti likho
            raise CustomException("Error during model training", e) # Loud Error Reporter ko bolo detail report de

    # Train kiye hue robot ka test lene aur report banane ka kaam
    def evaluate_model(self, X_test, y_test): # Test wala data aur asli answers lo
        try:
            logger.info("Starting model evaluation...") # Diary mein likho shuru ho gaya
            y_pred = self.model.predict(X_test) # Robot se test data par predictions karwao

            # Robot ke test marks calculate karo (Accuracy, Precision, Recall, F1)
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, average="weighted")
            recall = recall_score(y_test, y_pred, average="weighted")
            f1 = f1_score(y_test, y_pred, average="weighted")

            # Robot ke marks Diary mein likho
            logger.info(f"Accuracy Score: {accuracy}")
            logger.info(f"Precision Score: {precision}")
            logger.info(f"Recall Score: {recall}")
            logger.info(f"F1 Score: {f1}")

            # Robot ki galatiyon ki picture (Confusion Matrix) banao
            cm = confusion_matrix(y_test, y_pred)
            logger.info("Confusion Matrix calculated.") # Diary mein entry

            # Confusion Matrix ko sundar graph mein dikhao aur save karo
            plt.figure(figsize=(8, 6)) # Picture ka size set karo
            sns.heatmap(cm, annot=True, cmap="Blues", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
            plt.title("Confusion Matrix")
            plt.xlabel("Predicted Label") # Neeche likho yeh robot ke answers hain
            plt.ylabel("Actual Label") # Side mein likho yeh asli answers hain
            confusion_matrix_path = os.path.join(self.model_path, "confusion_matrix.png") # Picture kahan save karni hai
            plt.savefig(confusion_matrix_path) # Picture save karo
            plt.close() # Picture window band karo

            logger.info("Confusion Matrix saved successfully to %s", confusion_matrix_path) # Diary mein likho picture save ho gayi
            logger.info("Model Evaluation Finished Successfully.") # Diary entry

        except Exception as e:
            logger.error(f"Error during model evaluation: {e}") # Diary mein galti likho
            raise CustomException("Error during model evaluation", e) # Loud Error Reporter ko bolo detail report de

    # Robot Trainer ka main kaam (to-do list)
    def run(self):
        logger.info("Model Training Pipeline Step Started.") # Diary entry
        # Pehla kaam: Saaf data load karo
        X_train, X_test, y_train, y_test = self.load_data()
        self.train_model(X_train,y_train) # Doosra kaam: Robot ko sikhao
        self.evaluate_model(X_test,y_test) # Teesra kaam: Robot ka test lo
        logger.info("Model Training Pipeline Step Finished Successfully.") # Diary entry


# Yeh code tabhi chalega jab aap seedha is file ko run karoge
# Agar is file ko pipeline/training_pipeline.py se chalayenge, toh yeh hissa nahi chalega
if __name__ == "__main__":
    # Sirf testing ke liye, aap seedha model training chala sakte ho
    # Note: Iske liye data_processing pehle chalaya hua hona chahiye taki files exist karein
    trainer = ModelTraining() # Robot trainer banao
    trainer.run() # Trainer ka kaam shuru karo

```

*   **Explanation:** Yeh file hamare Robot Trainer ka blueprint (`ModelTraining` class) hai. Yeh bhi Diary Wala Robot aur Loud Error Reporter Robot ko import karta hai. `__init__` mein yeh apne liye workspace set karta hai, jahan se saaf data load karna hai aur jahan trained robot aur reports save karne hain, aur apna Decision Tree robot bhi bana leta hai ready hone ke liye. `load_data` function `joblib.load` use karke Data Cleaning Robot dwara save kiye gaye files ko wapas load karta hai. `train_model` asli training karta hai aur trained robot ko `joblib.dump` se save karta hai. `evaluate_model` test leta hai, marks (metrics) calculate karta hai, aur galatiyon ki picture (confusion matrix) bana ke save karta hai. `run` method iski to-do list chalati hai.

---

### 7. Master Controller: `training_pipeline.py` (The Recipe Book) ğŸ“œ

Ab time hai us file ka jo poore pipeline ko chalati hai, jaise ek recipe book ya ek master controller. Yeh file `DataProcessing` aur `ModelTraining` robots ko import karti hai aur unko sahi order mein chalne ka command deti hai.

Yeh pipeline folder mein rakhi hai:

```python
# pipeline/training_pipeline.py

# Apne helper robots ko bulao
from src.data_processing import DataProcessing
from src.model_training import ModelTraining
# Diary Wala Robot import karne ki yahan seedha zarurat nahi hai
# Kyunki woh helper robots ke andar hi use ho raha hai

# Yeh code tabhi chalega jab aap seedha is file ko run karoge (jo hum karna chahte hain)
if __name__ == "__main__":
    print("Pipeline Started! ğŸš€") # Console par print karo ki shuru ho gaya

    # Data Cleaning Robot ka kaam shuru karo
    data_processor = DataProcessing("artifacts/raw/data.csv") # Data Cleaning Robot banao aur raw data file batao
    data_processor.run() # Robot ko bolo apna kaam shuru kare (load, clean, split, save)

    print("Data Processing Done. âœ¨ Starting Model Training...") # Console par print karo next step shuru ho raha hai

    # Robot Trainer ka kaam shuru karo
    trainer =  ModelTraining() # Robot Trainer banao (yeh processed data khud dhund lega)
    trainer.run() # Robot ko bolo apna kaam shuru kare (load processed data, train, evaluate, save)

    print("Pipeline Finished Successfully! ğŸ‰") # Console par print karo ki khatam ho gaya

```

*   **Explanation:** Yeh file bahut simple hai. Jab aap is file ko run karoge (kyunki `if __name__ == "__main__":` check true hoga), yeh pehle `DataProcessing` robot banayegi, usko raw data file ka path degi, aur usko `run()` karne ko bolegi. Jab Data Processing robot apna sara kaam karke finish message likh dega diary mein aur files save kar dega, tab yeh `ModelTraining` robot banayegi aur usko `run()` karne ko bolegi. Robot Trainer processed data files load karega, Decision Tree robot ko train karega, aur uska test report save karega. Bas! Poora pipeline ek ke baad ek chal gaya!

---

### 8. Diagrams/Image Suggestions ğŸ–¼ï¸

Is pipeline ko aur bhi acche se samajhne ke liye, aap yeh pictures add kar sakte ho:

1.  **Image 1: Folder Structure:** Ek simple diagram jo `your_project_folder`, `artifacts`, `pipeline`, `src` folders aur unke andar ki main files dikhata hai. Jaise upar text mein banaya hai.
2.  **Image 2: Pipeline Flow:** Ek flowchart jaisa diagram. Dikhata hai ki `training_pipeline.py` shuru hota hai, fir woh `DataProcessing` ko call karta hai (data raw se processed mein jata hai), fir woh `ModelTraining` ko call karta hai (processed data se model aur reports bante hain). Arrows dikhao ki data kaise flow karta hai ek step se dusre step tak aur kya outputs bante hain.
    *   Box 1: `training_pipeline.py` (Start)
    *   Arrow to Box 2: `DataProcessing` Robot
    *   Inside Box 2: Loads `raw/data.csv`, Cleans, Splits
    *   Arrow from Box 2 to Box 3: `processed/X_train.pkl`, `y_train.pkl`, etc.
    *   Box 3: `ModelTraining` Robot
    *   Inside Box 3: Loads files from `processed`, Trains Model, Evaluates Model
    *   Arrow from Box 3 to Box 4: `models/model.pkl`, `models/confusion_matrix.png`
    *   Box 4: End (Results)
3.  **Image 3: Confusion Matrix Heatmap:** Wohi heatmap jo pichhle tutorial mein banaya tha, robot ke test results dikhane ke liye.

---

### 9. Glossary: Naye aur Purane Shabdon Ka Matlab ğŸ“–

Kuch aur naye ya repeat kiye gaye shabdon ko yaad rakhte hain:

*   **Pipeline:** Machine Learning project ke steps ko organize karne ka tareeka, jahan har step ek ke baad ek chalta hai. Jaise sandwich banane ka step-by-step recipe.
*   **Module / File (`.py`):** Python code wali files jo specific kaam karte hain. Hamare liye, yeh hamare helper robots ka ghar hai.
*   **Class:** Helper robot banane ka blueprint ya design. `DataProcessing` class se hum `DataProcessing` robot bana sakte hain.
*   **Method (`def function_name`):** Class ke andar ke functions, jo us specific robot ke kaam hain. Jaise `load_data` Data Processing robot ka ek kaam hai.
*   **`__init__`:** Special method jo class ka robot banate waqt sabse pehle chalta hai, setup karne ke liye.
*   **`run()`:** Ek common method jo hum banate hain taaki robot ka main kaam ya to-do list shuru ho jaye.
*   **`import`:** Doosre files mein banaye hue tools ya robots ko apne code mein use karne ke liye.
*   **`os.makedirs()`:** Folder banane ka command Python mein.
*   **`joblib.dump()` / `joblib.load()`:** Python objects (jaise data tables ya trained robots) ko files mein save karne aur wapas load karne ka special tool. Socho jaise special box mein packing aur unpacking. `.pkl` files banti hain isse.
*   **`src` Folder:** Source code files (hamare helper robots) ka folder.
*   **`pipeline` Folder:** Pipeline recipe file ka folder.
*   **`artifacts` Folder:** Jahan kaccha data, saaf data, trained robot, aur reports store hote hain. Storage room.
*   **Logger (`logger.py`):** Robot ki diary jo kaam ki progress aur problems note karti hai.
*   **Exception / CustomException (`custom_exception.py`):** Jab code mein galti hoti hai toh yeh chilla kar batata hai, aur `CustomException` ek detailed report deta hai.
*   **Features (`X`)**: Inputs (measurements).
*   **Target (`Y`)**: Output (Species).
*   **Outliers:** Shararti numbers jo baaki data se alag hain.
*   **Train/Test Split:** Data ko sikhane aur test karne ke parts mein baantna.
*   **Decision Tree:** Hamara Machine Learning robot jo seekhta hai.
*   **Accuracy / Confusion Matrix:** Robot ka test report aur galatiyon ki picture.

---

### 10. Summary: Poora Pipeline Kaise Chalta Hai? ğŸ‰

Aaj humne dekha ki kaise hum apne Decision Tree robot project ko organize kar sakte hain ek **Pipeline** bana kar.

1.  Hamare paas alag alag helper robots hain (`logger`, `custom_exception`, `data_processing`, `model_training`) jo `src` folder mein apne apne kamron mein rehte hain.
2.  `artifacts` folder hamara storage room hai jahan original data, saaf data, aur trained robot save hote hain.
3.  `pipeline/training_pipeline.py` file master controller hai. Jab hum isko run karte hain:
    *   Yeh pehle Data Processing Robot ko chalata hai.
    *   Data Processing Robot `artifacts/raw/data.csv` se data load karta hai, `SepalWidthCm` ke outliers theek karta hai, data ko train aur test parts mein divide karta hai, aur unko `artifacts/processed` folder mein `.pkl` files mein save kar deta hai `joblib` use karke. Har step diary mein note hota hai.
    *   Jab Data Processing Robot ka kaam khatam ho jata hai, Master Controller Model Training Robot ko chalata hai.
    *   Model Training Robot `artifacts/processed` folder se saaf data load karta hai `joblib` use karke, us data se Decision Tree robot ko train karta hai, trained robot ko `artifacts/models` folder mein `.pkl` file mein save karta hai, aur fir test data par robot ka performance check karta hai (Accuracy, Confusion Matrix) aur Confusion Matrix ki picture (`.png` file) bhi `artifacts/models` mein save karta hai. Yeh bhi sab kuch diary mein note karta hai.
    *   Jab dono robots apna kaam theek se kar lete hain, pipeline successfully finish ho jata hai.

Yeh organised tareeka project ko scalable (bada karne mein aasan), maintainable (theek karna aasan), aur collaboration friendly (agar doosre log help kar rahe hain toh unke liye samajhna aasan) banata hai.

Bahut achha kaam kiya! Aapne ek proper Machine Learning Pipeline ka basic structure samajh liya hai! Ab aap is code ko run kar sakte ho aur dekh sakte ho ki kaise aapki files `artifacts` folder mein save ho rahi hain aur `logs` folder mein diary entries likhi ja rahi hain.

Keep exploring! ğŸ˜ŠğŸ‘